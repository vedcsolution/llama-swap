recipe_version: '1'
name: cyankiwi/Qwen3-Next-80B-A3B-Thinking-AWQ-4bit
description: vLLM serving cyankiwi/Qwen3-Next-80B-A3B-Thinking-AWQ-4bit
model: cyankiwi/Qwen3-Next-80B-A3B-Thinking-AWQ-4bit
cluster_only: false
container: vllm-node:latest
mods:
  - mods/fix-qwen3-coder-next
defaults:
  port: 8000
  host: 0.0.0.0
  tensor_parallel: 2
  gpu_memory_utilization: 0.8
  max_model_len: 131072
env: {}
command: |
  vllm serve cyankiwi/Qwen3-Next-80B-A3B-Thinking-AWQ-4bit \
    --enable-auto-tool-choice \
    --tool-call-parser qwen3_coder \
    --gpu-memory-utilization {gpu_memory_utilization} \
    --host {host} \
    --port {port} \
    --kv-cache-dtype fp8 \
    --load-format fastsafetensors \
    --attention-backend flashinfer \
    --enable-prefix-caching \
    --max-model-len {max_model_len} \
    -tp {tensor_parallel} \
    --distributed-executor-backend ray