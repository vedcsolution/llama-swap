recipe_ref: models--unsloth--Qwen3.5-122B-A10B-GGUF
name: models--unsloth--Qwen3.5-122B-A10B-GGUF
model: unsloth/Qwen3.5-122B-A10B-GGUF:MXFP4_MOE
runtime: llama-cpp
backend: spark-llama-cpp
min_nodes: 1
max_nodes: 1
container: llama-cpp-spark:last
defaults:
  port: 8000
  host: 0.0.0.0
  n_gpu_layers: 99
  ctx_size: 16384
  temp: 0.6
  top_p: 0.95
  top_k: 20
  min_p: "0.00"
command: "llama-server \\\n    -hf {model} \\\n    --host {host} --port {port} \\\n    --n-gpu-layers {n_gpu_layers} \\\n    --ctx-size {ctx_size} \\\n    --temp {temp} --top-p {top_p} --top-k {top_k} --min-p {min_p} \\\n    --flash-attn on --jinja --no-webui\n"
