# Auto-generated by HF Models UI.
# You can fine-tune this recipe from /ui/#/models.

recipe_version: '1'
recipe_ref: autogen/models-unsloth-gpt-oss-120b-gguf-gguf-auto
name: unsloth/gpt-oss-120b-GGUF (GGUF auto)
description: Auto-generated from HF cache (gguf). Tune values in /ui/#/models.
model: unsloth/gpt-oss-120b-GGUF
runtime: llama-cpp
backend: spark-llama-cpp
container: llama-cpp-spark:last
defaults:
  ctx_size: 16384
  host: 0.0.0.0
  n_gpu_layers: 99
  port: 8000
  model: unsloth/gpt-oss-120b-GGUF
gguf_file: Q8_0/gpt-oss-120b-Q8_0-00001-of-00002.gguf
command: |-
  llama-server \
      -hf {model} \
      --ctx-size {ctx_size} \
      --n-gpu-layers {n_gpu_layers} \
      --port {port} --host {host} \
      --flash-attn on \
      --jinja \
      --no-webui
