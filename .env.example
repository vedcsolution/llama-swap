# Swap-Laboratories environment example

# App runtime
GIN_MODE=release

# Optional: absolute path to active config file
# LLAMA_SWAP_CONFIG_PATH=/home/USER/swap-laboratories/config.yaml

# Optional: backend override for recipes directory
# LLAMA_SWAP_RECIPES_BACKEND_DIR=/home/USER/spark-vllm-docker
# LLAMA_SWAP_RECIPES_BACKEND_OVERRIDE_FILE=/home/USER/swap-laboratories/.recipes_backend_dir
# LLAMA_SWAP_LOCAL_RECIPES_DIR=/home/USER/llama-swap/recipes

# Optional: TRT-LLM source image override (NVIDIA backend)
# LLAMA_SWAP_TRTLLM_SOURCE_IMAGE=nvcr.io/nvidia/tensorrt-llm/release:1.3.0rc3

# Optional: Hugging Face cache locations
# HF_HOME=/home/USER/.cache/huggingface
# TRANSFORMERS_CACHE=/home/USER/.cache/huggingface/hub

# Optional: listen address override (examples: :8080, 0.0.0.0:8080)
# LLAMA_SWAP_LISTEN=:8080

# Optional: global security headers middleware (1=true, 0=false)
# LLAMA_SWAP_SECURITY_HEADERS=1

# Optional: request rate limiting for inference endpoints only
# LLAMA_SWAP_RATE_LIMIT_RPM=120
# LLAMA_SWAP_RATE_LIMIT_BURST=10
# LLAMA_SWAP_RATE_LIMIT_TTL_SECONDS=600
