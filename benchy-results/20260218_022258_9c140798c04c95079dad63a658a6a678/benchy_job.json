{
  "id": "9c140798c04c95079dad63a658a6a678",
  "model": "Qwen/Qwen3-Coder-Next-vLLM-NEXT",
  "tokenizer": "Intel/Qwen3-Coder-Next-int4-AutoRound",
  "baseUrl": "http://127.0.0.1:8093/v1",
  "pp": [
    512,
    2048,
    8192
  ],
  "tg": [
    32,
    128
  ],
  "concurrency": [
    1
  ],
  "runs": 1,
  "outputDir": "/home/csolutions_ai/Swap-Laboratories/benchy-results/raw",
  "status": "done",
  "startedAt": "2026-02-18T02:22:33.239525926+01:00",
  "finishedAt": "2026-02-18T02:22:58.231781902+01:00",
  "exitCode": 0,
  "stdout": "llama-benchy (0.1.dev90+ge39fc28fb)\nDate: 2026-02-18 02:22:34\nBenchmarking model: Intel/Qwen3-Coder-Next-int4-AutoRound at http://127.0.0.1:8093/v1\nConcurrency levels: [1]\nLoading text from cache: /home/csolutions_ai/.cache/llama-benchy/cc6a0b5782734ee3b9069aa3b64cc62c.txt\nTotal tokens available in text corpus: 141518\nWarming up...\nWarmup (User only) complete. Delta: 8 tokens (Server: 29, Local: 21)\nWarmup (System+Empty) complete. Delta: 13 tokens (Server: 34, Local: 21)\nMeasuring latency using mode: api...\nAverage latency (api): 1.32 ms\nRunning test: pp=512, tg=32, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nRunning test: pp=512, tg=128, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nRunning test: pp=2048, tg=32, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nRunning test: pp=2048, tg=128, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nRunning test: pp=8192, tg=32, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nRunning test: pp=8192, tg=128, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nPrinting results in MD format:\n\n\n\n| model                                 |   test |            t/s |     peak t/s |      ttfr (ms) |   est_ppt (ms) |   e2e_ttft (ms) |\n|:--------------------------------------|-------:|---------------:|-------------:|---------------:|---------------:|----------------:|\n| Intel/Qwen3-Coder-Next-int4-AutoRound |  pp512 | 2907.56 ± 0.00 |              |  177.42 ± 0.00 |  176.09 ± 0.00 |   177.46 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |   tg32 |   28.14 ± 0.00 | 29.00 ± 0.00 |                |                |                 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |  pp512 | 2723.35 ± 0.00 |              |  189.33 ± 0.00 |  188.00 ± 0.00 |   189.37 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |  tg128 |   28.40 ± 0.00 | 29.00 ± 0.00 |                |                |                 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound | pp2048 | 3586.97 ± 0.00 |              |  572.28 ± 0.00 |  570.95 ± 0.00 |   572.31 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |   tg32 |   28.45 ± 0.00 | 29.00 ± 0.00 |                |                |                 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound | pp2048 | 3702.40 ± 0.00 |              |  554.48 ± 0.00 |  553.16 ± 0.00 |   554.53 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |  tg128 |   28.25 ± 0.00 | 29.00 ± 0.00 |                |                |                 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound | pp8192 | 3882.36 ± 0.00 |              | 2111.38 ± 0.00 | 2110.06 ± 0.00 |  2111.43 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |   tg32 |   28.40 ± 0.00 | 29.00 ± 0.00 |                |                |                 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound | pp8192 | 3870.72 ± 0.00 |              | 2117.47 ± 0.00 | 2116.14 ± 0.00 |  2117.50 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |  tg128 |   28.35 ± 0.00 | 29.00 ± 0.00 |                |                |                 |\n\nllama-benchy (0.1.dev90+ge39fc28fb)\ndate: 2026-02-18 02:22:34 | latency mode: api\n",
  "stderr": "PyTorch was not found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\nWarning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
}