{"id":"e28afb7c7459dce5cc500de11f57fcde","model":"Qwen/Qwen3-Coder-Next-vLLM-NEXT","tokenizer":"Intel/Qwen3-Coder-Next-int4-AutoRound","baseUrl":"http://127.0.0.1:8093/v1","pp":[512,2048,8192],"tg":[32,128],"concurrency":[1],"runs":1,"outputDir":"/tmp/llama-benchy-runs-direct-eager","status":"done","startedAt":"2026-02-18T02:15:29.982085965+01:00","finishedAt":"2026-02-18T02:16:18.696534715+01:00","exitCode":0,"stdout":"llama-benchy (0.1.dev90+ge39fc28fb)\nDate: 2026-02-18 02:15:32\nBenchmarking model: Intel/Qwen3-Coder-Next-int4-AutoRound at http://127.0.0.1:8093/v1\nConcurrency levels: [1]\nLoading text from cache: /home/csolutions_ai/.cache/llama-benchy/cc6a0b5782734ee3b9069aa3b64cc62c.txt\nTotal tokens available in text corpus: 141518\nWarming up...\nWarmup (User only) complete. Delta: 8 tokens (Server: 29, Local: 21)\nWarmup (System+Empty) complete. Delta: 13 tokens (Server: 34, Local: 21)\nMeasuring latency using mode: api...\nAverage latency (api): 3.56 ms\nRunning test: pp=512, tg=32, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nRunning test: pp=512, tg=128, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nRunning test: pp=2048, tg=32, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nRunning test: pp=2048, tg=128, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nRunning test: pp=8192, tg=32, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nRunning test: pp=8192, tg=128, depth=0, concurrency=1\n  Run 1/1 (batch size 1)...\nPrinting results in MD format:\n\n\n\n| model                                 |   test |            t/s |     peak t/s |      ttfr (ms) |   est_ppt (ms) |   e2e_ttft (ms) |\n|:--------------------------------------|-------:|---------------:|-------------:|---------------:|---------------:|----------------:|\n| Intel/Qwen3-Coder-Next-int4-AutoRound |  pp512 |  841.25 ± 0.00 |              |  612.18 ± 0.00 |  608.62 ± 0.00 |   612.22 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |   tg32 |   30.85 ± 0.00 | 31.00 ± 0.00 |                |                |                 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |  pp512 | 2037.38 ± 0.00 |              |  254.86 ± 0.00 |  251.30 ± 0.00 |   254.91 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |  tg128 |   29.85 ± 0.00 | 33.00 ± 0.00 |                |                |                 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound | pp2048 | 3020.17 ± 0.00 |              |  681.67 ± 0.00 |  678.11 ± 0.00 |   681.70 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |   tg32 |   31.03 ± 0.00 | 32.03 ± 0.00 |                |                |                 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound | pp2048 | 3457.06 ± 0.00 |              |  595.97 ± 0.00 |  592.41 ± 0.00 |   596.03 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |  tg128 |   31.48 ± 0.00 | 32.00 ± 0.00 |                |                |                 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound | pp8192 | 3693.02 ± 0.00 |              | 2221.80 ± 0.00 | 2218.24 ± 0.00 |  2221.84 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |   tg32 |   31.44 ± 0.00 | 32.46 ± 0.00 |                |                |                 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound | pp8192 | 3791.98 ± 0.00 |              | 2163.91 ± 0.00 | 2160.35 ± 0.00 |  2163.94 ± 0.00 |\n| Intel/Qwen3-Coder-Next-int4-AutoRound |  tg128 |   31.48 ± 0.00 | 32.00 ± 0.00 |                |                |                 |\n\nllama-benchy (0.1.dev90+ge39fc28fb)\ndate: 2026-02-18 02:15:32 | latency mode: api\n","stderr":"PyTorch was not found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"}